# WhisperX ASR API Service Configuration

# Hugging Face Token (REQUIRED for speaker diarization)
# Get your token from https://huggingface.co/settings/tokens
# Accept user agreements:
# - https://huggingface.co/pyannote/speaker-diarization-3.1
# - https://huggingface.co/pyannote/segmentation-3.0
HF_TOKEN=your_huggingface_token_here

# Device Configuration
# Options: cuda, cpu
DEVICE=cuda

# Compute Type
# Options: float16 (GPU), float32 (CPU), int8 (CPU, lower quality but faster)
COMPUTE_TYPE=float16

# Batch Size (adjust based on your GPU memory)
# Larger = faster but more memory
# Recommended: 16 for 8GB VRAM, 32 for 16GB+ VRAM
BATCH_SIZE=16

# Cache Directory (inside container)
CACHE_DIR=/.cache

# Model Preloading (OPTIONAL)
# Preload a specific model on startup to reduce first-request latency
# Options: tiny, base, small, medium, large-v2, large-v3
# Leave empty or comment out to disable preloading
PRELOAD_MODEL=large-v3
